{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TBL Model Development: Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor, GradientBoostingRegressor\n",
    "from joblib import Parallel, delayed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing Data Function (switching to using radius)\n",
    "\n",
    "def read_and_process_data(directory_path):\n",
    "    data_frames = []\n",
    "    columns_to_extract = ['radius_X', 'radius_Y', 'radius_Z', 'radius_Ox', 'radius_Oy', 'radius_Oz', 'Fx', 'Fy', 'Fz', 'Tx', 'Ty', 'Tz']\n",
    "\n",
    "    # Assuming each cycle has exactly 356 data points\n",
    "    total_data_points = 356\n",
    "\n",
    "    for file_name in os.listdir(directory_path):\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            file_path = os.path.join(directory_path, file_name)\n",
    "            participant = int(os.path.basename(file_path).split('_')[0])\n",
    "            cycle_id = os.path.basename(file_path).split('_')[1].split('.')[0]  # Extract cycle_id\n",
    "            intensity = cycle_id[:4]  # Extract the first four characters of cycle_id as intensity\n",
    "\n",
    "            # Read data from CSV and select only the desired columns\n",
    "            df = pd.read_csv(file_path, usecols=columns_to_extract)\n",
    "\n",
    "            # Add participant ID, cycle_id, and participant_cycle_id as features\n",
    "            df['Participant'] = participant\n",
    "            df['Cycle_ID'] = cycle_id\n",
    "            df['Participant_Cycle_ID'] = f\"{participant}_{cycle_id}\"\n",
    "            df['Intensity'] = intensity\n",
    "\n",
    "            # Since Data will get shuffled (idk why but shuffling makes the model so much better.. ??)\n",
    "            # So thus, need to store original index values \n",
    "            df['Original_Index'] = df.index\n",
    "\n",
    "            # # Add normalized_cycle_position\n",
    "            # df['Normalized_Cycle_Position'] = df.index / (total_data_points - 1)\n",
    "\n",
    "            # if (intensity == \"HIIT\"):\n",
    "            #     df['Intensity'] = 90\n",
    "            # else:\n",
    "            #     df['Intensity'] = 50\n",
    "            \n",
    "            # df['Intensity'] = intensity  # this is either \"HIIT\" or \"MICT\"\n",
    "\n",
    "            data_frames.append(df)\n",
    "\n",
    "    # Concatenate all data frames\n",
    "    processed_data = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "    # Merge with participant weights\n",
    "    weights_df = pd.read_csv(\"Participant Weights.csv\")\n",
    "    weights_df['Weight'] = weights_df['Weight'].astype(float)\n",
    "    weights_df['Wingspan'] = weights_df['Wingspan'].astype(float)\n",
    "    processed_data = pd.merge(processed_data, weights_df, left_on='Participant', right_on='Participant')\n",
    "\n",
    "    return processed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # Set up paths\n",
    "# data_directory = \"Processed Data for ML\"\n",
    "\n",
    "# # Read and process data\n",
    "# data = read_and_process_data(data_directory)\n",
    "\n",
    "# # Shuffle the data based on 'Participant_Cycle_ID'\n",
    "# data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# # Get unique participants\n",
    "# participants = data['Participant'].unique()\n",
    "\n",
    "# # Randomly select 16 participants for the train set and 4 participants for the test set\n",
    "# train_participants = np.random.choice(participants, size=16, replace=False)\n",
    "# test_participants = np.setdiff1d(participants, train_participants)\n",
    "\n",
    "# # Split the data into train and test based on the selected participants\n",
    "# train_data = data[data['Participant'].isin(train_participants)]\n",
    "# test_data = data[data['Participant'].isin(test_participants)]\n",
    "\n",
    "# # Specify the output columns\n",
    "# output_columns = ['Fx', 'Fy', 'Fz', 'Tx', 'Ty', 'Tz']\n",
    "\n",
    "# # Create X (input) and y (output) for train/validation/test\n",
    "# X_train = train_data.drop(output_columns, axis=1)  # Dropping the output columns to create input\n",
    "# y_train = train_data[output_columns]  # Creating output, each column will be a separate y\n",
    "\n",
    "# X_test = test_data.drop(output_columns, axis=1)  # Dropping the output columns to create input\n",
    "# y_test = test_data[output_columns]  # Creating output, each column will be a separate y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "data_directory = \"Processed Data for ML\"\n",
    "output_folder = \"Train and Test Data: 10 Fold\"\n",
    "\n",
    "# Read and process data\n",
    "data = read_and_process_data(data_directory)\n",
    "data[\"Intensity\"] = data[\"Intensity\"].map({\"HIIT\": 0.9, \"MICT\": 0.5})\n",
    "\n",
    "\n",
    "# Shuffle the data\n",
    "data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Get unique participants\n",
    "participants = data['Participant'].unique()\n",
    "\n",
    "# Initialize KFold cross-validator with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Create lists to store train and test sets for all folds\n",
    "all_X_train_sets = []\n",
    "all_y_train_sets = []\n",
    "all_X_test_sets = []\n",
    "all_y_test_sets = []\n",
    "\n",
    "fold_number = 1\n",
    "\n",
    "# Iterate over each fold\n",
    "for train_index, test_index in kf.split(participants):\n",
    "    train_participants = participants[train_index]\n",
    "    test_participants = participants[test_index]\n",
    "    \n",
    "    # Split the data into train and test based on the selected participants\n",
    "    train_data = data[data['Participant'].isin(train_participants)]\n",
    "    test_data = data[data['Participant'].isin(test_participants)]\n",
    "    \n",
    "    # Specify the output columns\n",
    "    output_columns = ['Fx', 'Fy', 'Fz', 'Tx', 'Ty', 'Tz']\n",
    "    \n",
    "    # Create X (input) and y (output) for train/validation/test\n",
    "    X_train = train_data.drop(output_columns, axis=1)  # Dropping the output columns to create input\n",
    "    y_train = train_data[output_columns]  # Creating output, each column will be a separate y\n",
    "    \n",
    "    X_test = test_data.drop(output_columns, axis=1)  # Dropping the output columns to create input\n",
    "    y_test = test_data[output_columns]  # Creating output, each column will be a separate y\n",
    "    \n",
    "    # Store train and test data\n",
    "    fold_folder = os.path.join(output_folder, f\"Fold_{fold_number}\")\n",
    "    #os.makedirs(fold_folder, exist_ok=True)\n",
    "    \n",
    "    # Save train and test data to CSV\n",
    "    #train_data.to_csv(os.path.join(fold_folder, \"train_data.csv\"), index=False)\n",
    "    #test_data.to_csv(os.path.join(fold_folder, \"test_data.csv\"), index=False)\n",
    "    \n",
    "    # Save participant numbers to text files\n",
    "    #np.savetxt(os.path.join(fold_folder, \"train_participants.txt\"), train_participants, fmt='%d')\n",
    "    #np.savetxt(os.path.join(fold_folder, \"test_participants.txt\"), test_participants, fmt='%d')\n",
    "    \n",
    "    # Append train and test sets to lists\n",
    "    all_X_train_sets.append(X_train)\n",
    "    all_y_train_sets.append(y_train)\n",
    "    all_X_test_sets.append(X_test)\n",
    "    all_y_test_sets.append(y_test)\n",
    "    \n",
    "    fold_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train models\n",
    "\n",
    "# # Define numerical and categorical features\n",
    "# numeric_features = ['radius_X', 'radius_Y', 'radius_Z', 'radius_Ox', 'radius_Oy', 'radius_Oz', 'Normalized_Cycle_Position', 'Weight', 'Wingspan']\n",
    "# categorical_features = ['Intensity']\n",
    "\n",
    "# # Create transformers for numerical and categorical features\n",
    "# numeric_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='median')),\n",
    "#     ('scaler', StandardScaler())\n",
    "# ])\n",
    "\n",
    "# categorical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "# ])\n",
    "\n",
    "# # Create a preprocessor that applies transformers to specific columns \n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', numeric_transformer, numeric_features),\n",
    "#         ('cat', categorical_transformer, categorical_features)\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # Create a pipeline with the preprocessor and the regressor\n",
    "# pipeline = Pipeline(steps=[\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('regressor', RandomForestRegressor())\n",
    "# ])\n",
    "\n",
    "# # Define the parameter grid for GridSearchCV\n",
    "# param_grid = {\n",
    "#     'regressor__n_estimators': [400, 450],  # Number of trees in the forest\n",
    "# }\n",
    "\n",
    "# # Create a GridSearchCV object\n",
    "# # grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# # Fit the GridSearchCV object to your training data\n",
    "# # grid_search.fit(X_train, y_train['Fx'])\n",
    "\n",
    "# # Create a GridSearchCV object\n",
    "# grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# # Fit the GridSearchCV object to your training data in parallel\n",
    "# with Parallel(n_jobs=-1):\n",
    "#     grid_search.fit(X_train, y_train['Fx'])\n",
    "\n",
    "# # Access the best parameters and best model\n",
    "# best_params = grid_search.best_params_\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "# # report model metrics\n",
    "\n",
    "# print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# # Get the mean cross-validated \"accuracy\" score of the best model\n",
    "# best_score = grid_search.best_score_\n",
    "\n",
    "# print(\"Mean Accuracy of Best Model (in Validation):\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "# from joblib import Parallel, delayed\n",
    "\n",
    "# # Define numerical and categorical features\n",
    "# # numeric_features = ['radius_X', 'radius_Y', 'radius_Z', 'radius_Ox', 'radius_Oy', 'radius_Oz', 'Normalized_Cycle_Position', 'Weight', 'Wingspan']\n",
    "# # Trying model without Normalized Cycle Position\n",
    "# numeric_features = ['radius_X', 'radius_Y', 'radius_Z', 'radius_Ox', 'radius_Oy', 'radius_Oz', 'Weight', 'Wingspan']\n",
    "# categorical_features = ['Intensity'] # i can try making numerical --> it worsened performance\n",
    "\n",
    "# # Create transformers for numerical and categorical features\n",
    "# numeric_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='median')),\n",
    "#     ('scaler', StandardScaler())\n",
    "# ])\n",
    "\n",
    "# categorical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "# ])\n",
    "\n",
    "# # Create a preprocessor that applies transformers to specific columns \n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', numeric_transformer, numeric_features),\n",
    "#         ('cat', categorical_transformer, categorical_features)\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # Define the parameter grid for GridSearchCV (training on just 400 (because that's the rough optimal from Fx training))\n",
    "# param_grid = {\n",
    "#     'regressor__n_estimators': [400],  # Number of trees in the forest\n",
    "# }\n",
    "\n",
    "# # Initialize dictionary to store best models\n",
    "# best_models = {}\n",
    "\n",
    "# # Train a model for each output column\n",
    "# for output_col in output_columns:\n",
    "#     # Create a pipeline with the preprocessor and the regressor\n",
    "#     pipeline = Pipeline(steps=[\n",
    "#         ('preprocessor', preprocessor),\n",
    "#         ('regressor', RandomForestRegressor())\n",
    "#     ])\n",
    "\n",
    "#     # Create a GridSearchCV object\n",
    "#     grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "#     # Fit the GridSearchCV object to your training data in parallel\n",
    "#     with Parallel(n_jobs=-1):\n",
    "#         grid_search.fit(X_train, y_train[output_col])\n",
    "\n",
    "#     # Access the best model\n",
    "#     best_models[output_col] = grid_search.best_estimator_\n",
    "\n",
    "#     # report model metrics\n",
    "#     print(\"Output Column:\", output_col)\n",
    "#     print(\"Best Parameters:\", grid_search.best_params_)\n",
    "#     print(\"Neg Mean Squared Error of Best Model (in Validation):\", grid_search.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1 completed.\n",
      "\n",
      "Fold 2 completed.\n",
      "\n",
      "Fold 3 completed.\n",
      "\n",
      "Fold 4 completed.\n",
      "\n",
      "Fold 5 completed.\n",
      "\n",
      "Fold 6 completed.\n",
      "\n",
      "Fold 7 completed.\n",
      "\n",
      "Fold 8 completed.\n",
      "\n",
      "Fold 9 completed.\n",
      "\n",
      "Fold 10 completed.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import gc  # Import the garbage collector module\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Define numerical features\n",
    "numeric_features = ['radius_X', 'radius_Y', 'radius_Z', 'radius_Ox', 'radius_Oy', 'radius_Oz', 'Weight', 'Wingspan', 'Intensity']\n",
    "#categorical_features = ['Intensity']\n",
    "\n",
    "# Create transformers for numerical and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# categorical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "# ])\n",
    "\n",
    "# Create a preprocessor that applies transformers to specific columns \n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define RandomForestRegressor with n_estimators=400\n",
    "regressor = XGBRegressor(objective='reg:squarederror', n_estimators=2000, max_depth=2000, eta=1.0, subsample=1.0, colsample_bytree=1.0, booster='gbtree')\n",
    "best_models = {}\n",
    "# Iterate over each fold\n",
    "for fold_number in range(1, 11):\n",
    "    X_train = all_X_train_sets[fold_number - 1]\n",
    "    y_train = all_y_train_sets[fold_number - 1]\n",
    "    \n",
    "    # Clear memory before starting a new fold\n",
    "    gc.collect()\n",
    "    \n",
    "    # Create a pipeline with the preprocessor and the regressor\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', regressor)\n",
    "    ])\n",
    "    \n",
    "    # Fit the pipeline to the training data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Store the best model for this output column in the corresponding fold's dictionary\n",
    "    print(f\"\\nFold {fold_number} completed.\")\n",
    "    \n",
    "    best_models[str(fold_number)] = pipeline\n",
    "    \n",
    "    # Clear memory after completing a fold\n",
    "    del X_train, y_train, pipeline\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mdpe_by_participant_cycle_ids(y_pred, y_test, X_test):\n",
    "    \"\"\"\n",
    "    Calculate Median Percentage Error (MDPE) for each unique participant_cycle_id for a specific output column.\n",
    "    \n",
    "    Args:\n",
    "    - y_pred (numpy array): Predicted values.\n",
    "    - y_test (numpy array): True values.\n",
    "    - X_test (DataFrame): DataFrame containing the test data including 'Participant_Cycle_ID'.\n",
    "    - output_column (str): Name of the output column.\n",
    "    \n",
    "    Returns:\n",
    "    - mdpe_scores (dict): Dictionary containing MDPE scores for each unique participant_cycle_id.\n",
    "    \"\"\"\n",
    "    mdpe_scores = []\n",
    "    \n",
    "    # Get unique participant_cycle_ids\n",
    "    unique_participant_cycle_ids = X_test['Participant_Cycle_ID'].unique()\n",
    "    \n",
    "    # Calculate MDPE for each unique participant_cycle_id\n",
    "    for unique_id in unique_participant_cycle_ids:\n",
    "        mask = X_test['Participant_Cycle_ID'] == unique_id\n",
    "        y_pred_id = y_pred[mask]\n",
    "        y_test_id = y_test[mask]\n",
    "        \n",
    "        # Exclude NaN values\n",
    "        mask_valid = ~np.isnan(y_test_id)\n",
    "        y_pred_id = y_pred_id[mask_valid]\n",
    "        y_test_id = y_test_id[mask_valid]\n",
    "        \n",
    "        mdpe = np.median((y_pred_id - y_test_id) / y_test_id * 100)\n",
    "        mdpe_scores.append(mdpe)\n",
    "        \n",
    "    return mdpe_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # getting MDPE based on test data set\n",
    "\n",
    "# # Initialize y_pred as a dictionary with keys for each output column\n",
    "# y_pred = {output_col: [] for output_col in output_columns}\n",
    "\n",
    "# mdpe_scores_outputs = {}\n",
    "# plot_data = []\n",
    "\n",
    "# for output_col in output_columns:\n",
    "#     y_pred[output_col] = best_models[output_col].predict(X_test)\n",
    "#     mdpe_scores = calculate_mdpe_by_participant_cycle_ids(y_pred, y_test, X_test, output_col)\n",
    "#     mdpe_scores_outputs[output_col] = mdpe_scores\n",
    "#     average = np.mean(mdpe_scores)\n",
    "#     std = np.std(mdpe_scores)\n",
    "#     print(\"Output Column:\", output_col)\n",
    "#     print(\"Average of MdPEs:\", average)\n",
    "#     print(\"Standard Deviation of MdPEs:\", std)\n",
    "#     # Add data for plotting\n",
    "#     for score in mdpe_scores:\n",
    "#         plot_data.append({'Output': output_col, 'MDPE': score})\n",
    "\n",
    "\n",
    "\n",
    "# # Create a box-and-whisker plot with stripplot\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# box_plot = sns.boxplot(x='Output', y='MDPE', data=pd.DataFrame(plot_data))\n",
    "# strip_plot = sns.stripplot(x='Output', y='MDPE', data=pd.DataFrame(plot_data), jitter=True, color=\".25\", marker='o',\n",
    "#                             size=2)  # Add individual data points with smaller dots\n",
    "# plt.title('Box-and-Whisker Plot of MDPE Scores for Each Output Column')\n",
    "\n",
    "# # Customize legend for the strip plot\n",
    "# legend_labels = {'Individual Data Points': 'o'}\n",
    "# handles, _ = strip_plot.get_legend_handles_labels()\n",
    "# box_plot.legend(handles, legend_labels.values(), title='Legend', loc='upper right')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1:\n",
      "Output Column: Fx\n",
      "Average of MdPEs: 1.9083750968877707e-05\n",
      "Standard Deviation of MdPEs: 0.00010408867476903624\n",
      "Output Column: Fy\n",
      "Average of MdPEs: -1.845728778403551e-05\n",
      "Standard Deviation of MdPEs: 8.34570558852216e-05\n",
      "Output Column: Fz\n",
      "Average of MdPEs: 1.0503079803728544e-05\n",
      "Standard Deviation of MdPEs: 0.0007873813283107059\n",
      "Output Column: Tx\n",
      "Average of MdPEs: -0.00020306960765353313\n",
      "Standard Deviation of MdPEs: 0.0016727773710903339\n",
      "Output Column: Ty\n",
      "Average of MdPEs: -0.0009504762931491426\n",
      "Standard Deviation of MdPEs: 0.0019142017957396048\n",
      "Output Column: Tz\n",
      "Average of MdPEs: 0.0036535090272869896\n",
      "Standard Deviation of MdPEs: 0.013074203103966\n",
      "\n",
      "Fold 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fs/zd5mdkv931gfzp78b7091dlm0000gn/T/ipykernel_24870/4012353036.py:70: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x='Output', y='MDPE', data=mdpe_df, palette='husl')  # Using 'husl' palette for more colorful plots\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Column: Fx\n",
      "Average of MdPEs: -7.599022158637541e-06\n",
      "Standard Deviation of MdPEs: 6.991419311161852e-05\n",
      "Output Column: Fy\n",
      "Average of MdPEs: -3.282369931275162e-05\n",
      "Standard Deviation of MdPEs: 0.00013273233917569232\n",
      "Output Column: Fz\n",
      "Average of MdPEs: -7.722628559284657e-05\n",
      "Standard Deviation of MdPEs: 0.0006049251472863541\n",
      "Output Column: Tx\n",
      "Average of MdPEs: 0.0006033501583266791\n",
      "Standard Deviation of MdPEs: 0.0027089312509877665\n",
      "Output Column: Ty\n",
      "Average of MdPEs: 0.00010399325957342144\n",
      "Standard Deviation of MdPEs: 0.00310245336407557\n",
      "Output Column: Tz\n",
      "Average of MdPEs: -0.0016242176955895255\n",
      "Standard Deviation of MdPEs: 0.02185158140203592\n",
      "\n",
      "Fold 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fs/zd5mdkv931gfzp78b7091dlm0000gn/T/ipykernel_24870/4012353036.py:70: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x='Output', y='MDPE', data=mdpe_df, palette='husl')  # Using 'husl' palette for more colorful plots\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Column: Fx\n",
      "Average of MdPEs: 2.5495365537368592e-05\n",
      "Standard Deviation of MdPEs: 8.647303411124051e-05\n",
      "Output Column: Fy\n",
      "Average of MdPEs: -1.9597839681500626e-05\n",
      "Standard Deviation of MdPEs: 8.449230270531251e-05\n",
      "Output Column: Fz\n",
      "Average of MdPEs: -0.00021693511750170793\n",
      "Standard Deviation of MdPEs: 0.0006338310576511873\n",
      "Output Column: Tx\n",
      "Average of MdPEs: 0.0003811975844531987\n",
      "Standard Deviation of MdPEs: 0.0024835243952265047\n",
      "Output Column: Ty\n",
      "Average of MdPEs: -0.0004416922424286671\n",
      "Standard Deviation of MdPEs: 0.002492949362468524\n",
      "Output Column: Tz\n",
      "Average of MdPEs: -0.0008688649365152686\n",
      "Standard Deviation of MdPEs: 0.02605524650311054\n",
      "\n",
      "Fold 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fs/zd5mdkv931gfzp78b7091dlm0000gn/T/ipykernel_24870/4012353036.py:70: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x='Output', y='MDPE', data=mdpe_df, palette='husl')  # Using 'husl' palette for more colorful plots\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Column: Fx\n",
      "Average of MdPEs: 1.3122486417960554e-06\n",
      "Standard Deviation of MdPEs: 8.51043186996329e-05\n",
      "Output Column: Fy\n",
      "Average of MdPEs: 8.128685191979114e-06\n",
      "Standard Deviation of MdPEs: 0.00010821575862764193\n",
      "Output Column: Fz\n",
      "Average of MdPEs: -1.3724446111087074e-05\n",
      "Standard Deviation of MdPEs: 0.00041985206658137997\n",
      "Output Column: Tx\n",
      "Average of MdPEs: 5.6589244148998304e-05\n",
      "Standard Deviation of MdPEs: 0.002872942505349806\n",
      "Output Column: Ty\n",
      "Average of MdPEs: -0.00010277155337244343\n",
      "Standard Deviation of MdPEs: 0.002366359204456872\n",
      "Output Column: Tz\n",
      "Average of MdPEs: -0.007533629298452613\n",
      "Standard Deviation of MdPEs: 0.022877864742258974\n",
      "\n",
      "Fold 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fs/zd5mdkv931gfzp78b7091dlm0000gn/T/ipykernel_24870/4012353036.py:70: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x='Output', y='MDPE', data=mdpe_df, palette='husl')  # Using 'husl' palette for more colorful plots\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Column: Fx\n",
      "Average of MdPEs: 1.256976731874036e-05\n",
      "Standard Deviation of MdPEs: 0.00010892601854822607\n",
      "Output Column: Fy\n",
      "Average of MdPEs: 6.414857036962272e-07\n",
      "Standard Deviation of MdPEs: 0.00010590379490215683\n",
      "Output Column: Fz\n",
      "Average of MdPEs: -0.00016388347564375095\n",
      "Standard Deviation of MdPEs: 0.0007579276305651319\n",
      "Output Column: Tx\n",
      "Average of MdPEs: -6.321416887740905e-05\n",
      "Standard Deviation of MdPEs: 0.002936561675749741\n",
      "Output Column: Ty\n",
      "Average of MdPEs: 0.0003849399391698928\n",
      "Standard Deviation of MdPEs: 0.0022344219697810388\n",
      "Output Column: Tz\n",
      "Average of MdPEs: -0.0030859394822621267\n",
      "Standard Deviation of MdPEs: 0.023211926486009858\n",
      "\n",
      "Fold 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fs/zd5mdkv931gfzp78b7091dlm0000gn/T/ipykernel_24870/4012353036.py:70: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x='Output', y='MDPE', data=mdpe_df, palette='husl')  # Using 'husl' palette for more colorful plots\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Column: Fx\n",
      "Average of MdPEs: -2.2401167979817737e-06\n",
      "Standard Deviation of MdPEs: 9.079751809712123e-05\n",
      "Output Column: Fy\n",
      "Average of MdPEs: -1.8167604297560346e-05\n",
      "Standard Deviation of MdPEs: 8.968220500500033e-05\n",
      "Output Column: Fz\n",
      "Average of MdPEs: -0.00013196336528655128\n",
      "Standard Deviation of MdPEs: 0.0004843539901648077\n",
      "Output Column: Tx\n",
      "Average of MdPEs: -0.00031462322274277874\n",
      "Standard Deviation of MdPEs: 0.00222604283231723\n",
      "Output Column: Ty\n",
      "Average of MdPEs: -0.0013470456754823262\n",
      "Standard Deviation of MdPEs: 0.002220611479446981\n",
      "Output Column: Tz\n",
      "Average of MdPEs: -0.0012075807595467792\n",
      "Standard Deviation of MdPEs: 0.029831718318870035\n",
      "\n",
      "Fold 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fs/zd5mdkv931gfzp78b7091dlm0000gn/T/ipykernel_24870/4012353036.py:70: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x='Output', y='MDPE', data=mdpe_df, palette='husl')  # Using 'husl' palette for more colorful plots\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Column: Fx\n",
      "Average of MdPEs: 5.116398873322664e-06\n",
      "Standard Deviation of MdPEs: 7.351587231592266e-05\n",
      "Output Column: Fy\n",
      "Average of MdPEs: 1.2015581741303449e-05\n",
      "Standard Deviation of MdPEs: 0.00011491556480256918\n",
      "Output Column: Fz\n",
      "Average of MdPEs: -4.0360920707050226e-05\n",
      "Standard Deviation of MdPEs: 0.0005614001063131314\n",
      "Output Column: Tx\n",
      "Average of MdPEs: -0.00044353204876659575\n",
      "Standard Deviation of MdPEs: 0.002791629309689647\n",
      "Output Column: Ty\n",
      "Average of MdPEs: 0.00025050384390666873\n",
      "Standard Deviation of MdPEs: 0.0017810428054596008\n",
      "Output Column: Tz\n",
      "Average of MdPEs: -8.24643547802049e-05\n",
      "Standard Deviation of MdPEs: 0.023651703549711765\n",
      "\n",
      "Fold 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fs/zd5mdkv931gfzp78b7091dlm0000gn/T/ipykernel_24870/4012353036.py:70: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x='Output', y='MDPE', data=mdpe_df, palette='husl')  # Using 'husl' palette for more colorful plots\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Column: Fx\n",
      "Average of MdPEs: -5.994457236458125e-06\n",
      "Standard Deviation of MdPEs: 7.092298951215011e-05\n",
      "Output Column: Fy\n",
      "Average of MdPEs: 1.8313065141347736e-05\n",
      "Standard Deviation of MdPEs: 8.612965853896658e-05\n",
      "Output Column: Fz\n",
      "Average of MdPEs: 0.00012562098539680507\n",
      "Standard Deviation of MdPEs: 0.0006909620410789737\n",
      "Output Column: Tx\n",
      "Average of MdPEs: -0.00016917151131225975\n",
      "Standard Deviation of MdPEs: 0.0022991485088636045\n",
      "Output Column: Ty\n",
      "Average of MdPEs: -2.4033196995894876e-05\n",
      "Standard Deviation of MdPEs: 0.002434365711165823\n",
      "Output Column: Tz\n",
      "Average of MdPEs: -0.002267133411371202\n",
      "Standard Deviation of MdPEs: 0.027491600568644376\n",
      "\n",
      "Fold 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fs/zd5mdkv931gfzp78b7091dlm0000gn/T/ipykernel_24870/4012353036.py:70: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x='Output', y='MDPE', data=mdpe_df, palette='husl')  # Using 'husl' palette for more colorful plots\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Column: Fx\n",
      "Average of MdPEs: 1.3630030197677356e-05\n",
      "Standard Deviation of MdPEs: 0.00013030317003103717\n",
      "Output Column: Fy\n",
      "Average of MdPEs: 1.7119142766248107e-07\n",
      "Standard Deviation of MdPEs: 0.00014037404827369837\n",
      "Output Column: Fz\n",
      "Average of MdPEs: 2.008273743362625e-05\n",
      "Standard Deviation of MdPEs: 0.0011250146414395355\n",
      "Output Column: Tx\n",
      "Average of MdPEs: 4.627570137135346e-05\n",
      "Standard Deviation of MdPEs: 0.0027140443334655938\n",
      "Output Column: Ty\n",
      "Average of MdPEs: 0.00022661685862858022\n",
      "Standard Deviation of MdPEs: 0.0029209638601033253\n",
      "Output Column: Tz\n",
      "Average of MdPEs: 0.0014942971542386732\n",
      "Standard Deviation of MdPEs: 0.018761307050293507\n",
      "\n",
      "Fold 10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fs/zd5mdkv931gfzp78b7091dlm0000gn/T/ipykernel_24870/4012353036.py:70: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x='Output', y='MDPE', data=mdpe_df, palette='husl')  # Using 'husl' palette for more colorful plots\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Column: Fx\n",
      "Average of MdPEs: -18.4618678460108\n",
      "Standard Deviation of MdPEs: 19.46094788874073\n",
      "Output Column: Fy\n",
      "Average of MdPEs: -8.56050118211754\n",
      "Standard Deviation of MdPEs: 10.726800969713494\n",
      "Output Column: Fz\n",
      "Average of MdPEs: -48.087184406206724\n",
      "Standard Deviation of MdPEs: 26.605162434837442\n",
      "Output Column: Tx\n",
      "Average of MdPEs: 3.088333970971483\n",
      "Standard Deviation of MdPEs: 16.59978424270368\n",
      "Output Column: Ty\n",
      "Average of MdPEs: -22.40521491080295\n",
      "Standard Deviation of MdPEs: 19.62399797795342\n",
      "Output Column: Tz\n",
      "Average of MdPEs: 11.211622992259294\n",
      "Standard Deviation of MdPEs: 24.75122506874575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fs/zd5mdkv931gfzp78b7091dlm0000gn/T/ipykernel_24870/4012353036.py:70: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x='Output', y='MDPE', data=mdpe_df, palette='husl')  # Using 'husl' palette for more colorful plots\n",
      "/var/folders/fs/zd5mdkv931gfzp78b7091dlm0000gn/T/ipykernel_24870/4012353036.py:98: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x='Output', y='MDPE', data=combined_mdpe_df, palette='husl')  # Using 'husl' palette for more colorful plots\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize y_pred as a dictionary with keys for each fold number\n",
    "y_pred = {fold_number: [] for fold_number in range(1, 11)}\n",
    "\n",
    "# Create a directory to store the y_pred for each fold and each output\n",
    "output_directory = \"GBM Outputs\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "mdpe_scores_outputs = {}\n",
    "\n",
    "# Accumulate MDPE scores across all folds for each output variable\n",
    "combined_mdpe_scores = {output_col: [] for output_col in output_columns}\n",
    "\n",
    "# Iterate over each fold\n",
    "for fold_number in range(1, 11):\n",
    "    X_test = all_X_test_sets[fold_number - 1]\n",
    "    y_test = all_y_test_sets[fold_number - 1]\n",
    "    \n",
    "    print(f\"\\nFold {fold_number}:\")\n",
    "    \n",
    "    # Predict y_pred for all output columns in this fold\n",
    "    y_pred[fold_number] = best_models[str(fold_number)].predict(X_test)\n",
    "\n",
    "    # Save selected columns from X_test, y_test, and y_pred for this fold as CSV\n",
    "    fold_output_directory = os.path.join(output_directory, f\"Fold_{fold_number}\")\n",
    "    os.makedirs(fold_output_directory, exist_ok=True)\n",
    "\n",
    "    # Convert the NumPy array to a pandas DataFrame\n",
    "    y_pred_df = pd.DataFrame(y_pred[fold_number], columns=output_columns)\n",
    "    \n",
    "    # Save train and test data to CSV\n",
    "    X_test.to_csv(os.path.join(fold_output_directory, \"X_test.csv\"), index=False)\n",
    "    y_test.to_csv(os.path.join(fold_output_directory, \"y_test.csv\"), index=False)\n",
    "    y_pred_df.to_csv(os.path.join(fold_output_directory, \"y_pred.csv\"), index=False)\n",
    "\n",
    "    # Calculate MDPE scores for this fold and each output column\n",
    "    mdpe_scores_list = []\n",
    "    for i, output_col in enumerate(output_columns):\n",
    "        y_pred_fold_output = y_pred[fold_number][:, i]\n",
    "        \n",
    "        mdpe_scores = calculate_mdpe_by_participant_cycle_ids(y_pred_fold_output, y_test[output_col], X_test)\n",
    "        mdpe_scores_outputs[(fold_number, output_col)] = mdpe_scores\n",
    "        mdpe_scores_list.append(pd.DataFrame({'Output': [output_col]*len(mdpe_scores), 'MDPE': mdpe_scores}))\n",
    "        \n",
    "        # Append MDPE scores to combined_mdpe_scores\n",
    "        combined_mdpe_scores[output_col].extend(mdpe_scores)\n",
    "        \n",
    "        average = np.mean(mdpe_scores)\n",
    "        std = np.std(mdpe_scores)\n",
    "        print(f\"Output Column: {output_col}\")\n",
    "        print(\"Average of MdPEs:\", average)\n",
    "        print(\"Standard Deviation of MdPEs:\", std)\n",
    "        \n",
    "        # Save average and standard deviation of MdPEs to the output directory\n",
    "        with open(os.path.join(output_directory, f\"Fold_{fold_number}_mdpe_scores.txt\"), 'a') as f:\n",
    "            f.write(f\"Output Column: {output_col}\\n\")\n",
    "            f.write(f\"Average of MdPEs: {average}\\n\")\n",
    "            f.write(f\"Standard Deviation of MdPEs: {std}\\n\\n\")\n",
    "    \n",
    "    # Combine MDPE scores for all output columns in this fold\n",
    "    mdpe_df = pd.concat(mdpe_scores_list)\n",
    "    \n",
    "    # Plot MDPE scores for this fold and all output columns\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.boxplot(x='Output', y='MDPE', data=mdpe_df, palette='husl')  # Using 'husl' palette for more colorful plots\n",
    "    plt.title(f'Box-and-Whisker Plot of MDPE Scores for Fold {fold_number}')\n",
    "    plt.ylabel('MDPE')\n",
    "    plt.xlabel('Output Column')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.savefig(os.path.join(fold_output_directory, f\"MDPE_plot.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# Calculate the mean and standard deviation of MDPE scores for each output variable across all folds\n",
    "average_mdpe_scores = {}\n",
    "std_mdpe_scores = {}\n",
    "\n",
    "for output_col in output_columns:\n",
    "    average_mdpe_scores[output_col] = np.mean(combined_mdpe_scores[output_col])\n",
    "    std_mdpe_scores[output_col] = np.std(combined_mdpe_scores[output_col])\n",
    "\n",
    "# Write mean and standard deviation of MDPEs to a txt file\n",
    "with open(os.path.join(output_directory, \"average_mdpe_scores.txt\"), 'w') as f:\n",
    "    for output_col in output_columns:\n",
    "        f.write(f\"Output Column: {output_col}\\n\")\n",
    "        f.write(f\"Average of MdPEs across 10 folds: {average_mdpe_scores[output_col]}\\n\")\n",
    "        f.write(f\"Standard Deviation of MdPEs across 10 folds: {std_mdpe_scores[output_col]}\\n\\n\")\n",
    "\n",
    "# Combine MDPE scores for all output columns across all folds\n",
    "combined_mdpe_df = pd.concat([pd.DataFrame({'Output': [output_col]*len(combined_mdpe_scores[output_col]), 'MDPE': combined_mdpe_scores[output_col]}) for output_col in output_columns], ignore_index=True)\n",
    "\n",
    "# Plot combined MDPE scores for all output columns\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x='Output', y='MDPE', data=combined_mdpe_df, palette='husl')  # Using 'husl' palette for more colorful plots\n",
    "plt.title('Box-and-Whisker Plot of Combined MDPE Scores for All Folds')\n",
    "plt.ylabel('MDPE')\n",
    "plt.xlabel('Output Column')\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig(os.path.join(output_directory, \"combined_MDPE_plot.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS307",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
